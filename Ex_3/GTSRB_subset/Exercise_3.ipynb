{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "#### Pattern Recognization and Machine Learning\n",
    "#### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score as ac\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'target', 'target_names', 'images', 'DESCR'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9833333333333333, 0.9416666666666667, 0.5972222222222222, 0.9611111111111111]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "digits = load_digits()\n",
    "print(digits.keys())\n",
    "\n",
    "plt.gray() \n",
    "plt.imshow(digits.images[0]) \n",
    "plt.show()\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data,digits.target, test_size=0.2)\n",
    "\n",
    "KNN = KNeighborsClassifier()\n",
    "LDA = LinearDiscriminantAnalysis()\n",
    "SVC= SVC()\n",
    "LR = LogisticRegression()\n",
    "\n",
    "classifiers = [KNN,LDA,SVC,LR]\n",
    "accuracy = []\n",
    "\n",
    "for key in classifiers:\n",
    "    key.fit(x_train,y_train)\n",
    "    y_predic = key.predict(x_test)\n",
    "    accuracy.append(accuracy_score(y_test,y_predic))\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "#### Train classifiers for the GTSRB task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1/202\n",
      "Processing image 2/202\n",
      "Processing image 3/202\n",
      "Processing image 4/202\n",
      "Processing image 5/202\n",
      "Processing image 6/202\n",
      "Processing image 7/202\n",
      "Processing image 8/202\n",
      "Processing image 9/202\n",
      "Processing image 10/202\n",
      "Processing image 11/202\n",
      "Processing image 12/202\n",
      "Processing image 13/202\n",
      "Processing image 14/202\n",
      "Processing image 15/202\n",
      "Processing image 16/202\n",
      "Processing image 17/202\n",
      "Processing image 18/202\n",
      "Processing image 19/202\n",
      "Processing image 20/202\n",
      "Processing image 21/202\n",
      "Processing image 22/202\n",
      "Processing image 23/202\n",
      "Processing image 24/202\n",
      "Processing image 25/202\n",
      "Processing image 26/202\n",
      "Processing image 27/202\n",
      "Processing image 28/202\n",
      "Processing image 29/202\n",
      "Processing image 30/202\n",
      "Processing image 31/202\n",
      "Processing image 32/202\n",
      "Processing image 33/202\n",
      "Processing image 34/202\n",
      "Processing image 35/202\n",
      "Processing image 36/202\n",
      "Processing image 37/202\n",
      "Processing image 38/202\n",
      "Processing image 39/202\n",
      "Processing image 40/202\n",
      "Processing image 41/202\n",
      "Processing image 42/202\n",
      "Processing image 43/202\n",
      "Processing image 44/202\n",
      "Processing image 45/202\n",
      "Processing image 46/202\n",
      "Processing image 47/202\n",
      "Processing image 48/202\n",
      "Processing image 49/202\n",
      "Processing image 50/202\n",
      "Processing image 51/202\n",
      "Processing image 52/202\n",
      "Processing image 53/202\n",
      "Processing image 54/202\n",
      "Processing image 55/202\n",
      "Processing image 56/202\n",
      "Processing image 57/202\n",
      "Processing image 58/202\n",
      "Processing image 59/202\n",
      "Processing image 60/202\n",
      "Processing image 61/202\n",
      "Processing image 62/202\n",
      "Processing image 63/202\n",
      "Processing image 64/202\n",
      "Processing image 65/202\n",
      "Processing image 66/202\n",
      "Processing image 67/202\n",
      "Processing image 68/202\n",
      "Processing image 69/202\n",
      "Processing image 70/202\n",
      "Processing image 71/202\n",
      "Processing image 72/202\n",
      "Processing image 73/202\n",
      "Processing image 74/202\n",
      "Processing image 75/202\n",
      "Processing image 76/202\n",
      "Processing image 77/202\n",
      "Processing image 78/202\n",
      "Processing image 79/202\n",
      "Processing image 80/202\n",
      "Processing image 81/202\n",
      "Processing image 82/202\n",
      "Processing image 83/202\n",
      "Processing image 84/202\n",
      "Processing image 85/202\n",
      "Processing image 86/202\n",
      "Processing image 87/202\n",
      "Processing image 88/202\n",
      "Processing image 89/202\n",
      "Processing image 90/202\n",
      "Processing image 91/202\n",
      "Processing image 92/202\n",
      "Processing image 93/202\n",
      "Processing image 94/202\n",
      "Processing image 95/202\n",
      "Processing image 96/202\n",
      "Processing image 97/202\n",
      "Processing image 98/202\n",
      "Processing image 99/202\n",
      "Processing image 100/202\n",
      "Processing image 101/202\n",
      "Processing image 102/202\n",
      "Processing image 103/202\n",
      "Processing image 104/202\n",
      "Processing image 105/202\n",
      "Processing image 106/202\n",
      "Processing image 107/202\n",
      "Processing image 108/202\n",
      "Processing image 109/202\n",
      "Processing image 110/202\n",
      "Processing image 111/202\n",
      "Processing image 112/202\n",
      "Processing image 113/202\n",
      "Processing image 114/202\n",
      "Processing image 115/202\n",
      "Processing image 116/202\n",
      "Processing image 117/202\n",
      "Processing image 118/202\n",
      "Processing image 119/202\n",
      "Processing image 120/202\n",
      "Processing image 121/202\n",
      "Processing image 122/202\n",
      "Processing image 123/202\n",
      "Processing image 124/202\n",
      "Processing image 125/202\n",
      "Processing image 126/202\n",
      "Processing image 127/202\n",
      "Processing image 128/202\n",
      "Processing image 129/202\n",
      "Processing image 130/202\n",
      "Processing image 131/202\n",
      "Processing image 132/202\n",
      "Processing image 133/202\n",
      "Processing image 134/202\n",
      "Processing image 135/202\n",
      "Processing image 136/202\n",
      "Processing image 137/202\n",
      "Processing image 138/202\n",
      "Processing image 139/202\n",
      "Processing image 140/202\n",
      "Processing image 141/202\n",
      "Processing image 142/202\n",
      "Processing image 143/202\n",
      "Processing image 144/202\n",
      "Processing image 145/202\n",
      "Processing image 146/202\n",
      "Processing image 147/202\n",
      "Processing image 148/202\n",
      "Processing image 149/202\n",
      "Processing image 150/202\n",
      "Processing image 151/202\n",
      "Processing image 152/202\n",
      "Processing image 153/202\n",
      "Processing image 154/202\n",
      "Processing image 155/202\n",
      "Processing image 156/202\n",
      "Processing image 157/202\n",
      "Processing image 158/202\n",
      "Processing image 159/202\n",
      "Processing image 160/202\n",
      "Processing image 161/202\n",
      "Processing image 162/202\n",
      "Processing image 163/202\n",
      "Processing image 164/202\n",
      "Processing image 165/202\n",
      "Processing image 166/202\n",
      "Processing image 167/202\n",
      "Processing image 168/202\n",
      "Processing image 169/202\n",
      "Processing image 170/202\n",
      "Processing image 171/202\n",
      "Processing image 172/202\n",
      "Processing image 173/202\n",
      "Processing image 174/202\n",
      "Processing image 175/202\n",
      "Processing image 176/202\n",
      "Processing image 177/202\n",
      "Processing image 178/202\n",
      "Processing image 179/202\n",
      "Processing image 180/202\n",
      "Processing image 181/202\n",
      "Processing image 182/202\n",
      "Processing image 183/202\n",
      "Processing image 184/202\n",
      "Processing image 185/202\n",
      "Processing image 186/202\n",
      "Processing image 187/202\n",
      "Processing image 188/202\n",
      "Processing image 189/202\n",
      "Processing image 190/202\n",
      "Processing image 191/202\n",
      "Processing image 192/202\n",
      "Processing image 193/202\n",
      "Processing image 194/202\n",
      "Processing image 195/202\n",
      "Processing image 196/202\n",
      "Processing image 197/202\n",
      "Processing image 198/202\n",
      "Processing image 199/202\n",
      "Processing image 200/202\n",
      "Processing image 201/202\n",
      "Processing image 202/202\n",
      "X shape: (202, 64, 64)\n",
      "F shape: (202, 256)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from simplelbp import local_binary_pattern\n",
    "\n",
    "def load_data(folder):\n",
    "    \"\"\" \n",
    "    Load all images from subdirectories of\n",
    "    'folder'. The subdirectory name indicates\n",
    "    the class.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = []          # Images go here\n",
    "    y = []          # Class labels go here\n",
    "    classes = []    # All class names go here\n",
    "    \n",
    "    subdirectories = glob.glob(folder + \"/*\")\n",
    "    \n",
    "    # Loop over all folders\n",
    "    for d in subdirectories:\n",
    "        \n",
    "        # Find all files from this folder\n",
    "        files = glob.glob(d + os.sep + \"*.jpg\")\n",
    "        \n",
    "        # Load all files\n",
    "        for name in files:\n",
    "            \n",
    "            # Load image and parse class name\n",
    "            img = plt.imread(name)\n",
    "            class_name = name.split(os.sep)[-2]\n",
    "\n",
    "            # Convert class names to integer indices:\n",
    "            if class_name not in classes:\n",
    "                classes.append(class_name)\n",
    "            \n",
    "            class_idx = classes.index(class_name)\n",
    "            \n",
    "            X.append(img)\n",
    "            y.append(class_idx)\n",
    "    \n",
    "    # Convert python lists to contiguous numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def extract_lbp_features(X, P = 8, R = 5):\n",
    "    \"\"\"\n",
    "    Extract LBP features from all input samples.\n",
    "    - R is radius parameter\n",
    "    - P is the number of angles for LBP\n",
    "    \"\"\"\n",
    "    \n",
    "    F = [] # Features are stored here\n",
    "    \n",
    "    N = X.shape[0]\n",
    "    for k in range(N):\n",
    "        \n",
    "        print(\"Processing image {}/{}\".format(k+1, N))\n",
    "        \n",
    "        image = X[k, ...]\n",
    "        lbp = local_binary_pattern(image, P, R)\n",
    "        hist = np.histogram(lbp, bins=range(257))[0]\n",
    "        F.append(hist)\n",
    "\n",
    "    return np.array(F)\n",
    "\n",
    "# Test our loader\n",
    "\n",
    "X, y = load_data(\".\")\n",
    "F = extract_lbp_features(X)\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"F shape: \" + str(F.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test train using cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Score KNeighborsClassifier = 0.975909090909091\n",
      "Mean score LinearDiscriminantAnalysis = 0.985\n",
      "Mean score SVC = 0.534090909090909\n",
      "Mean Score LogisticRegression = 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train,  y_test = train_test_split(F, y, test_size=0.20, random_state=50) # Feature matrix and y label vector\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_neigh = KNeighborsClassifier (n_neighbors=3)\n",
    "model_neigh.fit (X_train, y_train)\n",
    "scores_neigh = cross_val_score(model_neigh, F, y, cv=10)\n",
    "mean_scores_neigh=np.mean(scores_neigh)\n",
    "print ('Mean Score KNeighborsClassifier = ',end='')\n",
    "print (mean_scores_neigh)\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "model_LDA = LinearDiscriminantAnalysis()\n",
    "model_LDA.fit (X_train, y_train)\n",
    "scores_LDA = cross_val_score(model_LDA, F, y, cv=10)\n",
    "mean_scores_LDA=np.mean(scores_LDA)\n",
    "print ('Mean score LinearDiscriminantAnalysis = ',end='')\n",
    "print (mean_scores_LDA)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "model_SVC = SVC (gamma='auto')\n",
    "model_SVC.fit (X_train, y_train)\n",
    "scores_SVC = cross_val_score(model_SVC, F, y, cv=10)\n",
    "mean_scores_SVC=np.mean(scores_SVC)\n",
    "print ('Mean score SVC = ',end='')\n",
    "print (mean_scores_SVC)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model_LR = LogisticRegression()\n",
    "model_LR.fit (X_train, y_train)\n",
    "scores_LR = cross_val_score(model_LR, F, y, cv=10)\n",
    "mean_scores_LR=np.mean(scores_LR)\n",
    "print ('Mean Score LogisticRegression = ',end='')\n",
    "print (mean_scores_LR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "#### Train ensemble methods with the GTSRB data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train,  y_test = train_test_split(F, y, test_size=0.20, random_state=50) \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Train a 100-tree Random Forest classifier with the GTSRB and compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classifier scores = 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfr = RandomForestClassifier(n_estimators=100)\n",
    "rfr.fit(X_train , y_train)\n",
    "y_pred = rfr.predict(X_test)\n",
    "print ('Random Forest classifier scores = ',end='')\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print (score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Train a 100-tree Extremely Randomized Trees classifier with the GTSRB and compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extremely Randomized Trees classifier scores = 0.975609756097561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "rfr = ExtraTreesClassifier(n_estimators=100)\n",
    "rfr.fit(X_train , y_train)\n",
    "y_pred = rfr.predict(X_test)\n",
    "print ('Extremely Randomized Trees classifier scores = ',end='')\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print (score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Train a 100-tree AdaBoost classifier with the GTSRB and compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost classifier scores = 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "rfr = AdaBoostClassifier(n_estimators=100)\n",
    "rfr.fit(X_train , y_train)\n",
    "y_pred = rfr.predict(X_test)\n",
    "print ('AdaBoost classifier scores = ',end='')\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print (score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Train a 100-tree Gradient Boosted Tree classifier with the GTSRB and compute the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosted Tree classifier score = 0.926829268292683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "rfr = GradientBoostingClassifier(n_estimators=100)\n",
    "rfr.fit(X_train , y_train)\n",
    "y_pred = rfr.predict(X_test)\n",
    "print ('Gradient Boosted Tree classifier score = ',end='')\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print (score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
